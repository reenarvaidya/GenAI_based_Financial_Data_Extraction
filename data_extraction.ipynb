{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f083ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 bordered, 1 borderless, 94.6ms\n",
      "Speed: 1.8ms preprocess, 94.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 borderless, 102.7ms\n",
      "Speed: 1.6ms preprocess, 102.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bordered, 1 borderless, 98.9ms\n",
      "Speed: 1.7ms preprocess, 98.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 borderlesss, 98.8ms\n",
      "Speed: 1.6ms preprocess, 98.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 (no detections), 93.2ms\n",
      "Speed: 1.8ms preprocess, 93.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 86.4ms\n",
      "Speed: 1.6ms preprocess, 86.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 86.5ms\n",
      "Speed: 1.7ms preprocess, 86.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 88.8ms\n",
      "Speed: 1.9ms preprocess, 88.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 91.5ms\n",
      "Speed: 1.7ms preprocess, 91.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 98.6ms\n",
      "Speed: 1.9ms preprocess, 98.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 borderless, 99.6ms\n",
      "Speed: 1.7ms preprocess, 99.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 (no detections), 80.6ms\n",
      "Speed: 1.5ms preprocess, 80.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 (no detections), 88.5ms\n",
      "Speed: 1.8ms preprocess, 88.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x512 (no detections), 102.1ms\n",
      "Speed: 2.2ms preprocess, 102.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 (no detections), 91.8ms\n",
      "Speed: 1.6ms preprocess, 91.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 96.0ms\n",
      "Speed: 1.7ms preprocess, 96.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 bordered, 91.8ms\n",
      "Speed: 1.8ms preprocess, 91.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 bordered, 93.8ms\n",
      "Speed: 1.8ms preprocess, 93.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 97.7ms\n",
      "Speed: 1.9ms preprocess, 97.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 90.4ms\n",
      "Speed: 1.9ms preprocess, 90.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 117.1ms\n",
      "Speed: 1.7ms preprocess, 117.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 (no detections), 99.2ms\n",
      "Speed: 2.4ms preprocess, 99.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 (no detections), 91.9ms\n",
      "Speed: 1.6ms preprocess, 91.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 85.9ms\n",
      "Speed: 1.6ms preprocess, 85.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 94.8ms\n",
      "Speed: 1.8ms preprocess, 94.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 bordered, 94.8ms\n",
      "Speed: 1.6ms preprocess, 94.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 89.0ms\n",
      "Speed: 1.6ms preprocess, 89.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 100.5ms\n",
      "Speed: 1.8ms preprocess, 100.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 84.4ms\n",
      "Speed: 1.6ms preprocess, 84.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 87.8ms\n",
      "Speed: 1.7ms preprocess, 87.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 85.3ms\n",
      "Speed: 1.7ms preprocess, 85.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 85.8ms\n",
      "Speed: 1.6ms preprocess, 85.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 bordered, 97.8ms\n",
      "Speed: 1.6ms preprocess, 97.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image , ImageEnhance , ImageFilter\n",
    "import google.generativeai as genai\n",
    "from pdf2image import convert_from_path\n",
    "import numpy as np\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from ultralytics import YOLO \n",
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "# load model\n",
    "yolo_model = YOLO('best.pt')\n",
    "# set model parameters\n",
    "yolo_model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "yolo_model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "yolo_model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "yolo_model.overrides['max_det'] = 10  # maximum number of detections per image\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyD4dDDiFZ-bLjcICMnv6wV7t4pUqYmXBeo\")\n",
    "\n",
    "json_model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "## PDF - Desired Images (involves deleting irrelavant pages and cropping required pagesimages)\n",
    "poppler_path = r'C:\\Users\\User\\Downloads\\poppler-24.08.0\\poppler-24.08.0\\Library\\bin'\n",
    "folder_path = r\"C:\\Users\\User\\Desktop\\Reena\\Financial_Data_Table_Extraction\\pdfs\"\n",
    "output_path = r'C:\\Users\\User\\Desktop\\Reena\\Financial_Data_Table_Extraction\\Output_images_01'\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "os.environ['TESSDATA_PREFIX'] = r'C:\\Program Files\\Tesseract-OCR\\tessdata'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path,filename)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    pages = convert_from_path(file_path,poppler_path=poppler_path,dpi=300)\n",
    "    for i, img in enumerate(pages):\n",
    "        results = yolo_model(img)\n",
    "        boxes = results[0].boxes.xyxy\n",
    "\n",
    "        sub_folder = os.path.join(output_path, base_name)\n",
    "        os.makedirs(sub_folder, exist_ok=True)\n",
    "        \n",
    "\n",
    "        for j, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cropped = img.crop((x1, y1, x2, y2))\n",
    "           \n",
    "            \n",
    "            cropped_path = os.path.join(sub_folder, f\"page_{i+1}_table_{j+1}.jpg\")\n",
    "            \n",
    "            extracted_text = pytesseract.image_to_string(img, config='--oem 3 --psm 4')\n",
    "            # Save extracted text to file\n",
    "            \n",
    "            json_path = os.path.join(sub_folder, f\"page_{i+1}_table_{j+1}.json\")\n",
    "            \n",
    "\n",
    "            prompt =f\"\"\"\n",
    "            This is a table extracted from a financial PDF:\n",
    "\n",
    "            {extracted_text}\n",
    "\n",
    "            Your task:\n",
    "            1. ONLY if the text contains **financial data for standalone or consolidated statements**, extract and convert them into **quarter-wise JSON**.\n",
    "            2. Match each quarter and its associated metrics carefully.\n",
    "            3. Do not hallucinate values. Skip if the data is ambiguous or missing.\n",
    "\n",
    "            Your output format:\n",
    "            {{\n",
    "            \"Standalone_financial_results_for_all_months\": {{\n",
    "            \"Quarter ended [date]\": {{\n",
    "            \"Revenue from operations\": float,\n",
    "            \"Other income\": float,\n",
    "            ...\n",
    "            }},\n",
    "            ...2w\n",
    "            }},\n",
    "            \"Consolidated_financial_results_for_all_months\": {{\n",
    "            ...\n",
    "            }}\n",
    "            }}\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            response = json_model.generate_content(prompt)\n",
    "            if \"The provided text\" in response.text:\n",
    "                continue\n",
    "            else :\n",
    "                with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3e037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
