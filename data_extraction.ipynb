{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f083ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Reena\\Financial_Data_Table_Extraction\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 bordered, 1 borderless, 100.0ms\n",
      "Speed: 1.8ms preprocess, 100.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 borderless, 100.5ms\n",
      "Speed: 2.0ms preprocess, 100.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 bordered, 1 borderless, 96.8ms\n",
      "Speed: 1.5ms preprocess, 96.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 borderlesss, 95.1ms\n",
      "Speed: 2.2ms preprocess, 95.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 (no detections), 95.4ms\n",
      "Speed: 2.0ms preprocess, 95.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 90.0ms\n",
      "Speed: 1.5ms preprocess, 90.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 85.6ms\n",
      "Speed: 1.4ms preprocess, 85.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 101.0ms\n",
      "Speed: 1.5ms preprocess, 101.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 92.1ms\n",
      "Speed: 2.0ms preprocess, 92.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 98.0ms\n",
      "Speed: 1.8ms preprocess, 98.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 borderless, 92.2ms\n",
      "Speed: 1.5ms preprocess, 92.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 (no detections), 98.7ms\n",
      "Speed: 1.9ms preprocess, 98.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 (no detections), 98.9ms\n",
      "Speed: 1.8ms preprocess, 98.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x512 (no detections), 100.6ms\n",
      "Speed: 2.0ms preprocess, 100.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 (no detections), 87.9ms\n",
      "Speed: 2.0ms preprocess, 87.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 93.2ms\n",
      "Speed: 1.7ms preprocess, 93.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 bordered, 94.9ms\n",
      "Speed: 1.8ms preprocess, 94.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 bordered, 102.0ms\n",
      "Speed: 1.6ms preprocess, 102.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 95.7ms\n",
      "Speed: 1.8ms preprocess, 95.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 97.7ms\n",
      "Speed: 2.1ms preprocess, 97.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 100.0ms\n",
      "Speed: 1.9ms preprocess, 100.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 (no detections), 107.2ms\n",
      "Speed: 2.2ms preprocess, 107.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 (no detections), 86.0ms\n",
      "Speed: 2.1ms preprocess, 86.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 87.7ms\n",
      "Speed: 1.9ms preprocess, 87.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 93.8ms\n",
      "Speed: 2.0ms preprocess, 93.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 bordered, 94.0ms\n",
      "Speed: 2.1ms preprocess, 94.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 93.4ms\n",
      "Speed: 2.0ms preprocess, 93.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 96.2ms\n",
      "Speed: 1.9ms preprocess, 96.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 91.0ms\n",
      "Speed: 1.7ms preprocess, 91.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 86.4ms\n",
      "Speed: 1.7ms preprocess, 86.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 (no detections), 91.3ms\n",
      "Speed: 2.2ms preprocess, 91.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 borderless, 94.2ms\n",
      "Speed: 1.6ms preprocess, 94.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 bordered, 102.3ms\n",
      "Speed: 2.0ms preprocess, 102.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image , ImageEnhance , ImageFilter\n",
    "import google.generativeai as genai\n",
    "from pdf2image import convert_from_path\n",
    "import numpy as np\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from ultralytics import YOLO \n",
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "# load model\n",
    "yolo_model = YOLO('')\n",
    "# set model parameters\n",
    "yolo_model.overrides['conf'] = 0.25  # NMS confidence threshold\n",
    "yolo_model.overrides['iou'] = 0.45  # NMS IoU threshold\n",
    "yolo_model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n",
    "yolo_model.overrides['max_det'] = 10  # maximum number of detections per image\n",
    "\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "json_model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "\n",
    "poppler_path = \"\"\n",
    "folder_path = \"\"\n",
    "output_path = \"\"\n",
    "pytesseract.pytesseract.tesseract_cmd = \"\"\n",
    "os.environ['TESSDATA_PREFIX'] =  \"\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    base_name = os.path.splitext(filename)[0]  # Get filename without extension\n",
    "\n",
    "    # Convert each page of the PDF to an image\n",
    "    pages = convert_from_path(file_path, poppler_path=poppler_path, dpi=300)\n",
    "\n",
    "    # Loop through each page image\n",
    "    for i, img in enumerate(pages):\n",
    "        # Use YOLO model to detect tables in the image\n",
    "        results = yolo_model(img)\n",
    "        boxes = results[0].boxes.xyxy  # Get bounding boxes for detected tables\n",
    "\n",
    "        # Create a subfolder to save cropped tables and results\n",
    "        sub_folder = os.path.join(output_path, base_name)\n",
    "        os.makedirs(sub_folder, exist_ok=True)\n",
    "\n",
    "        # Loop through each detected table box\n",
    "        for j, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = map(int, box)  # Convert box coordinates to integers\n",
    "            cropped = img.crop((x1, y1, x2, y2))  # Crop the table from the page\n",
    "\n",
    "            # Define path to save cropped image\n",
    "            cropped_path = os.path.join(sub_folder, f\"page_{i+1}_table_{j+1}.jpg\")\n",
    "\n",
    "            # Extract text from the original full page image using Tesseract OCR\n",
    "            extracted_text = pytesseract.image_to_string(img, config='--oem 3 --psm 4')\n",
    "\n",
    "            # Define path to save the JSON output\n",
    "            json_path = os.path.join(sub_folder, f\"page_{i+1}_table_{j+1}.json\")\n",
    "\n",
    "            # Create prompt to send to the LLM for JSON conversion\n",
    "            prompt = f\"\"\"\n",
    "            This is a table extracted from a financial PDF:\n",
    "\n",
    "            {extracted_text}\n",
    "\n",
    "            Your task:\n",
    "            1. ONLY if the text contains **financial data for standalone or consolidated statements**, extract and convert them into **quarter-wise JSON**.\n",
    "            2. Match each quarter and its associated metrics carefully.\n",
    "            3. Do not hallucinate values. Skip if the data is ambiguous or missing.\n",
    "\n",
    "            Your output format:\n",
    "            {{\n",
    "            \"Standalone_financial_results_for_all_months\": {{\n",
    "            \"Quarter ended [date]\": {{\n",
    "            \"Revenue from operations\": float,\n",
    "            \"Other income\": float,\n",
    "            ...\n",
    "            }},\n",
    "            ...\n",
    "            }},\n",
    "            \"Consolidated_financial_results_for_all_months\": {{\n",
    "            ...\n",
    "            }}\n",
    "            }}\n",
    "            \"\"\"\n",
    "\n",
    "            # Send prompt to the LLM (json_model) for generation\n",
    "            response = json_model.generate_content(prompt)\n",
    "\n",
    "            # Skip saving if model returns a generic response\n",
    "            if \"The provided text\" in response.text:\n",
    "                continue\n",
    "            else:\n",
    "                # Save the LLM-generated JSON response to file\n",
    "                with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
